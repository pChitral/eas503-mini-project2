{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "from sqlite3 import Error\n",
    "def create_connection(db_file, delete_db=False):\n",
    "    \n",
    "    import os\n",
    "    if delete_db and os.path.exists(db_file):\n",
    "        os.remove(db_file)\n",
    "\n",
    "    conn = None\n",
    "    try:\n",
    "        conn = sqlite3.connect(db_file)\n",
    "        conn.execute(\"PRAGMA foreign_keys = 1\")\n",
    "    except Error as e:\n",
    "        print(e)\n",
    "\n",
    "    return conn\n",
    "\n",
    "\n",
    "def create_table(conn, create_table_sql, drop_table_name=None):\n",
    "    \n",
    "    if drop_table_name: # You can optionally pass drop_table_name to drop the table. \n",
    "        try:\n",
    "            c = conn.cursor()\n",
    "            c.execute(\"\"\"DROP TABLE IF EXISTS %s\"\"\" % (drop_table_name))\n",
    "        except Error as e:\n",
    "            print(e)\n",
    "    \n",
    "    try:\n",
    "        c = conn.cursor()\n",
    "        c.execute(create_table_sql)\n",
    "    except Error as e:\n",
    "        print(e)\n",
    "        \n",
    "def execute_sql_statement(sql_statement, conn):\n",
    "    cur = conn.cursor()\n",
    "    cur.execute(sql_statement)\n",
    "\n",
    "    rows = cur.fetchall()\n",
    "\n",
    "    return rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 'British Isles'),\n",
       " (2, 'Central America'),\n",
       " (3, 'Eastern Europe'),\n",
       " (4, 'North America'),\n",
       " (5, 'Northern Europe'),\n",
       " (6, 'Scandinavia'),\n",
       " (7, 'South America'),\n",
       " (8, 'Southern Europe'),\n",
       " (9, 'Western Europe')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "region_list = []\n",
    "with open(\"data.csv\") as file:\n",
    "    i = iter(file)\n",
    "    i.__next__()\n",
    "    for line in i:\n",
    "        if line.split(\"\\t\")[4] not in region_list:\n",
    "            region_list.append(line.split(\"\\t\")[4])\n",
    "        else: continue\n",
    "region_list.sort()\n",
    "\n",
    "for i in range(len(region_list)):\n",
    "    region_list[i] = (i+1 , region_list[i]) \n",
    "    \n",
    "region_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "conno = create_connection(\"pel.db\", True)\n",
    "create_table_sql = \"\"\"CREATE TABLE [regn] (\n",
    "    [RegionID] Integer not null primary key,\n",
    "    [Region] Text not null\n",
    "    );\n",
    "    \"\"\"\n",
    "create_table(conno, create_table_sql)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = conno.cursor()\n",
    "\n",
    "c.executemany('INSERT INTO regn VALUES(?, ?);',region_list)\n",
    "\n",
    "conno.commit()\n",
    "conno.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_table_sql = \"\"\"CREATE TABLE [Region] (\n",
    "    [RegionID] Integer not null primary key,\n",
    "    [Region] Text not null\n",
    "    );\n",
    "    \"\"\"\n",
    "conn= create_connection(\"hello.db\", True)\n",
    "create_table(conn, create_table_sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "InterfaceError",
     "evalue": "Error binding parameter 0 - probably unsupported type.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInterfaceError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/q4/72ybtynd5sjf5ppl_5vpsw080000gn/T/ipykernel_82971/725518187.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mconn_norm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mregion\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mregion_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0minsert_region\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconn_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mregion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/q4/72ybtynd5sjf5ppl_5vpsw080000gn/T/ipykernel_82971/725518187.py\u001b[0m in \u001b[0;36minsert_region\u001b[0;34m(conn, values)\u001b[0m\n\u001b[1;32m      4\u001b[0m             VALUES(?) '''\n\u001b[1;32m      5\u001b[0m     \u001b[0mcur\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcursor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mcur\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msql\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcur\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlastrowid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInterfaceError\u001b[0m: Error binding parameter 0 - probably unsupported type."
     ]
    }
   ],
   "source": [
    "def insert_region(conn, values):\n",
    "    \n",
    "    sql = ''' INSERT INTO Region(Region)\n",
    "            VALUES(?) '''\n",
    "    cur = conn.cursor()\n",
    "    cur.execute(sql, values)\n",
    "    return cur.lastrowid\n",
    "    \n",
    "# That the insert_region function is ready, we can start putting in values in the table as follows!\n",
    "conn_norm = create_connection(\"hello.db\")\n",
    "with conn_norm:\n",
    "    for region in region_list:\n",
    "        insert_region(conn_norm, (region, ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fetching all the degrees in a list\n",
    "sql_statement = \"SELECT Region, RegionID from Region\"\n",
    "regions_from_table = execute_sql_statement(sql_statement, conn)\n",
    "regions_from_table\n",
    "\n",
    "region_to_regionid_dictionary = {}\n",
    "\n",
    "for i in range(len(regions_from_table)):\n",
    "    region_to_regionid_dictionary[regions_from_table[i][0]] = regions_from_table[i][1]\n",
    "    \n",
    "region_to_regionid_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 'Argentina', 7),\n",
       " (2, 'Austria', 9),\n",
       " (3, 'Belgium', 9),\n",
       " (4, 'Brazil', 7),\n",
       " (5, 'Canada', 4),\n",
       " (6, 'Denmark', 5),\n",
       " (7, 'Finland', 6),\n",
       " (8, 'France', 9),\n",
       " (9, 'Germany', 9),\n",
       " (10, 'Ireland', 1),\n",
       " (11, 'Italy', 8),\n",
       " (12, 'Mexico', 2),\n",
       " (13, 'Norway', 6),\n",
       " (14, 'Poland', 3),\n",
       " (15, 'Portugal', 8),\n",
       " (16, 'Spain', 8),\n",
       " (17, 'Sweden', 5),\n",
       " (18, 'Switzerland', 9),\n",
       " (19, 'UK', 1),\n",
       " (20, 'USA', 4),\n",
       " (21, 'Venezuela', 7)]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "country_region_list = []\n",
    "with open(\"data.csv\") as file:\n",
    "    i = iter(file)\n",
    "    i.__next__()\n",
    "    for line in i:\n",
    "        if [line.split(\"\\t\")[3], region_to_regionid_dictionary[line.split(\"\\t\")[4]]] not in country_region_list:\n",
    "            country_region_list.append([line.split(\"\\t\")[3], region_to_regionid_dictionary[line.split(\"\\t\")[4]]])\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "country_region_list.sort()\n",
    "\n",
    "for i, country in enumerate(country_region_list):\n",
    "    country_region_list[i] =  (i+1, country_region_list[i][0], country_region_list[i][1])\n",
    "country_region_list\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_table_sql = \"\"\"CREATE TABLE [Country] (\n",
    "[CountryID] integer not null Primary key,\n",
    "[Country] Text not null,\n",
    "[RegionID] integer not null,\n",
    "foreign key(RegionID) References Region(RegionID)\n",
    ");\n",
    "\n",
    "\"\"\"\n",
    "conn = create_connection(\"hello.db\")\n",
    "\n",
    "# Running the query by passing it to the `create_table` function\n",
    "create_table(conn, create_table_sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_country_region(conn, values):\n",
    "    sql = ''' INSERT INTO Country(Country, RegionID)\n",
    "            VALUES(?, ?) '''\n",
    "    cur = conn.cursor()\n",
    "    cur.execute(sql, values)\n",
    "    return cur.lastrowid\n",
    "\n",
    "# That the insert_country_region function is ready, we can start putting in values in the table as follows!\n",
    "conn_norm = create_connection(\"hello.db\")\n",
    "\n",
    "with conn_norm:\n",
    "    for country_region in country_region_list:\n",
    "        try:\n",
    "            insert_country_region(conn_norm, (country_region[0], country_region[1]))\n",
    "        except Error:\n",
    "            print(Error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step2_create_region_to_regionid_dictionary(normalized_database_filename):\n",
    "\n",
    "    # BEGIN SOLUTION\n",
    "    # Fetching all the Regions from our Region table\n",
    "    conn = create_connection(normalized_database_filename)\n",
    "    sql_statement = \"SELECT Region, RegionID from Region\"\n",
    "    regions_from_table = execute_sql_statement(sql_statement, conn)\n",
    "\n",
    "    region_to_regionid_dictionary = {}\n",
    "\n",
    "    for i in range(len(regions_from_table)):\n",
    "        region_to_regionid_dictionary[regions_from_table[i]\n",
    "                                      [0]] = regions_from_table[i][1]\n",
    "\n",
    "    return region_to_regionid_dictionary\n",
    "\n",
    "    # END SOLUTION\n",
    "def step4_create_country_to_countryid_dictionary(normalized_database_filename):\n",
    "\n",
    "    # BEGIN SOLUTION\n",
    "    conn = create_connection(normalized_database_filename)\n",
    "    sql_statement = \"SELECT Country, CountryID from country\"\n",
    "    countries_from_table = execute_sql_statement(sql_statement, conn)\n",
    "\n",
    "    country_to_countryid_dictionary = {}\n",
    "\n",
    "    for i in range(len(countries_from_table)):\n",
    "        country_to_countryid_dictionary[countries_from_table[i]\n",
    "                                        [0]] = countries_from_table[i][1]\n",
    "\n",
    "    return country_to_countryid_dictionary\n",
    "\n",
    "    # END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 'Alejandra', 'Camino', 'Gran Via, 1', 'Madrid', 16),\n",
       " (2, 'Alexander', 'Feuer', 'Heerstr. 22', 'Leipzig', 9),\n",
       " (3, 'Ana', 'Trujillo', 'Avda. de la Constitucion 2222', 'Mexico D.F.', 12),\n",
       " (4, 'Anabela', 'Domingues', 'Av. Ines de Castro, 414', 'Sao Paulo', 4),\n",
       " (5, 'Andre', 'Fonseca', 'Av. Brasil, 442', 'Campinas', 4),\n",
       " (6, 'Ann', 'Devon', '35 King George', 'London', 19),\n",
       " (7, 'Annette', 'Roulet', '1 rue Alsace-Lorraine', 'Toulouse', 8),\n",
       " (8, 'Antonio', 'Moreno', 'Mataderos  2312', 'Mexico D.F.', 12),\n",
       " (9, 'Aria', 'Cruz', 'Rua Oros, 92', 'Sao Paulo', 4),\n",
       " (10, 'Art', 'Braunschweiger', 'P.O. Box 555', 'Lander', 20)]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalized_database_filename = \"normalized.db\"\n",
    "country_to_countryid_dictionary = step4_create_country_to_countryid_dictionary(normalized_database_filename)\n",
    "country_to_countryid_dictionary\n",
    "\n",
    "step5_data = []\n",
    "\n",
    "with open(\"data.csv\") as file:\n",
    "    i = iter(file)\n",
    "    i.__next__()\n",
    "    for line in i:\n",
    "        if [line.split(\"\\t\")[0], line.split(\"\\t\")[1], line.split(\"\\t\")[2], country_to_countryid_dictionary[line.split(\"\\t\")[3]]] not in step5_data:\n",
    "            step5_data.append(\n",
    "                [line.split(\"\\t\")[0].split(\" \")[0], line.split(\"\\t\")[0].split(\" \")[1],  line.split(\"\\t\")[1], line.split(\"\\t\")[2], country_to_countryid_dictionary[line.split(\"\\t\")[3]]])\n",
    "        else:\n",
    "            continue\n",
    "step5_data.sort()\n",
    "for i, stuff in enumerate(step5_data):\n",
    "    step5_data[i] = (i+1, stuff[0], stuff[1], stuff[2], stuff[3], stuff[4])\n",
    "step5_data[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Alejandra Camino'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conn = create_connection(normalized_database_filename)\n",
    "sql_statement = \"SELECT FirstName, LastName from Customer\"\n",
    "customers_from_table = execute_sql_statement(sql_statement, conn)\n",
    "\n",
    "customer_to_customerid_dictionary = {}\n",
    "customers_from_table[0]\n",
    "\n",
    "\n",
    "for i in range(len(customers_from_table)):\n",
    "    key = str(customers_from_table[i][0]) + \" \" + str(customers_from_table[i][1])\n",
    "    customer_to_customerid_dictionary[key] = i + 1\n",
    "\n",
    "# return customer_to_customerid_dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 'Beverages', 'Soft drinks, coffees, teas, beers, and ales'),\n",
       " (2,\n",
       "  'Condiments',\n",
       "  'Sweet and savory sauces, relishes, spreads, and seasonings'),\n",
       " (3, 'Confections', 'Desserts, candies, and sweet breads'),\n",
       " (4, 'Dairy Products', 'Cheeses'),\n",
       " (5, 'Grains/Cereals', 'Breads, crackers, pasta, and cereal'),\n",
       " (6, 'Meat/Poultry', 'Prepared meats'),\n",
       " (7, 'Produce', 'Dried fruit and bean curd'),\n",
       " (8, 'Seafood', 'Seaweed and fish')]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prod_cat_list = []\n",
    "with open(\"data.csv\") as file:\n",
    "    i = iter(file)\n",
    "    i.__next__()\n",
    "    for line in i:\n",
    "        if [line.split(\"\\t\")[6].split(\",\")[0], line.split(\"\\t\")[7].split(\"/\")[0]]  not in prod_cat_list:\n",
    "            prod_cat_list.append([line.split(\"\\t\")[6].split(\",\")[0], line.split(\"\\t\")[7].split(\"/\")[0]])\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "newMaal = []\n",
    "for i in range(len(prod_cat_list)):\n",
    "    if [prod_cat_list[i][0].split(\";\")[0], prod_cat_list[i][1].split(\";\")[0]] not in newMaal:\n",
    "        newMaal.append([prod_cat_list[i][0].split(\";\")[0], prod_cat_list[i][1].split(\";\", 1)[0]])\n",
    "newMaal.sort()    \n",
    "  \n",
    "\n",
    "for i in range(len(newMaal)):\n",
    "    newMaal[i] = (i+1, newMaal[i][0], newMaal[i][1])\n",
    "newMaal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "malo = []\n",
    "with open(\"data.csv\") as file:\n",
    "    i = iter(file)\n",
    "    i.__next__()\n",
    "    for i in line:\n",
    "        malo.append(i.split(\",\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Beverages': 1,\n",
       " 'Condiments': 2,\n",
       " 'Confections': 3,\n",
       " 'Dairy Products': 4,\n",
       " 'Grains/Cereals': 5,\n",
       " 'Meat/Poultry': 6,\n",
       " 'Produce': 7,\n",
       " 'Seafood': 8}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalized_database_filename = \"normalized.db\"\n",
    "conn = create_connection(normalized_database_filename)\n",
    "sql_statement = \"SELECT ProductCategory, ProductCategoryID from ProductCategory\"\n",
    "prod_cat_from_table = execute_sql_statement(sql_statement, conn)\n",
    "\n",
    "productcategory_to_productcategoryid_dictionary = {}\n",
    "\n",
    "for i in range(len(prod_cat_from_table)):\n",
    "    productcategory_to_productcategoryid_dictionary[prod_cat_from_table[i]\n",
    "                                    [0]] = prod_cat_from_table[i][1]\n",
    "\n",
    "productcategory_to_productcategoryid_dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 'Alice Mutton', '39', 6),\n",
       " (2, 'Aniseed Syrup', '10', 2),\n",
       " (3, 'Boston Crab Meat', '18.4', 8),\n",
       " (4, 'Carnarvon Tigers', '62.5', 8),\n",
       " (5, 'Chang', '19', 1),\n",
       " (6, \"Chef Anton's Cajun Seasoning\", '22', 2),\n",
       " (7, \"Chef Anton's Gumbo Mix\", '21.35', 2),\n",
       " (8, 'Filo Mix', '7', 5),\n",
       " (9, 'Geitost', '2.5', 4),\n",
       " (10, 'Genen Shouyu', '15.5', 2),\n",
       " (11, 'Gnocchi di nonna Alice', '38', 5),\n",
       " (12, 'Gorgonzola Telino', '12.5', 4),\n",
       " (13, 'Gravad lax', '26', 8),\n",
       " (14, 'Guarana Fantastica', '4.5', 1),\n",
       " (15, 'Gudbrandsdalsost', '36', 4),\n",
       " (16, 'Gula Malacca', '19.45', 2),\n",
       " (17, 'Gumbar Gummibarchen', '31.23', 3),\n",
       " (18, \"Gustaf's Knackebrod\", '21', 5),\n",
       " (19, 'Ikura', '31', 8),\n",
       " (20, \"Jack's New England Clam Chowder\", '9.65', 8),\n",
       " (21, 'Louisiana Fiery Hot Pepper Sauce', '21.05', 2),\n",
       " (22, 'NuNuCa Nu-Nougat-Creme', '14', 3),\n",
       " (23, 'Pate chinois', '24', 6),\n",
       " (24, 'Pavlova', '17.45', 3),\n",
       " (25, 'Perth Pasties', '32.8', 6),\n",
       " (26, 'Queso Cabrales', '21', 4),\n",
       " (27, 'Queso Manchego La Pastora', '38', 4),\n",
       " (28, 'Raclette Courdavault', '55', 4),\n",
       " (29, 'Rossle Sauerkraut', '45.6', 7),\n",
       " (30, 'Sasquatch Ale', '14', 1),\n",
       " (31, 'Schoggi Schokolade', '43.9', 3),\n",
       " (32, \"Sir Rodney's Marmalade\", '81', 3),\n",
       " (33, \"Sir Rodney's Scones\", '10', 3),\n",
       " (34, 'Steeleye Stout', '18', 1),\n",
       " (35, 'Tarte au sucre', '49.3', 3),\n",
       " (36, 'Teatime Chocolate Biscuits', '9.2', 3),\n",
       " (37, 'Thuringer Rostbratwurst', '123.79', 6),\n",
       " (38, 'Tofu', '23.25', 7),\n",
       " (39, 'Tourtiere', '7.45', 6),\n",
       " (40, 'Tunnbrod', '9', 5),\n",
       " (41, \"Uncle Bob's Organic Dried Pears\", '30', 7),\n",
       " (42, 'Valkoinen suklaa', '16.25', 3)]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "product_list = []\n",
    "with open(\"data.csv\") as file:\n",
    "    i = iter(file)\n",
    "    header = i.__next__().strip().split()\n",
    "\n",
    "    for line in i:\n",
    "        if [line.split(\"\\t\")[5].split(\";\")[0], line.split(\"\\t\")[8].split(\";\", 1)[0], productcategory_to_productcategoryid_dictionary[line.split(\"\\t\")[6].split(\";\", 1)[0]] ] not in product_list:\n",
    "            product_list.append([line.split(\"\\t\")[5].split(\";\")[0], line.split(\"\\t\")[8].split(\";\", 1)[0], productcategory_to_productcategoryid_dictionary[line.split(\"\\t\")[6].split(\";\", 1)[0]] ])\n",
    "product_list.sort()\n",
    "\n",
    "for i in range(len(product_list)):\n",
    "    product_list[i] = (i+1, product_list[i][0], product_list[i][1],product_list[i][2])\n",
    "product_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "product_list = []\n",
    "with open(\"data.csv\") as file:\n",
    "    i = iter(file)\n",
    "    header = i.__next__().strip().split()\n",
    "\n",
    "    for line in i:\n",
    "        if [line.split(\"\\t\")[5], line.split(\"\\t\")[8]] not in product_list:\n",
    "            product_list.append([line.split(\"\\t\")[5], line.split(\"\\t\")[8]])\n",
    "prodMaal = []\n",
    "for i in range(len(product_list)):\n",
    "    if [product_list[i][0].split(\";\")[0], product_list[i][1].split(\";\")[0]] not in prodMaal:\n",
    "        prodMaal.append([product_list[i][0].split(\";\")[0], product_list[i][1].split(\";\")[0]])\n",
    "len(prodMaal)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'_io.TextIOWrapper' object has no attribute 'split'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/q4/72ybtynd5sjf5ppl_5vpsw080000gn/T/ipykernel_82971/804805323.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mheader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprod_name_raw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\t\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mprod_price_raw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\t\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mprod_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprod_name_raw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\";\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mprod_prices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprod_price_raw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\";\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: '_io.TextIOWrapper' object has no attribute 'split'"
     ]
    }
   ],
   "source": [
    "with open(\"data.csv\") as file:\n",
    "    i = iter(file)\n",
    "    header = i.__next__().strip().split()\n",
    "    prod_name_raw = i.__next__().split(\"\\t\")[5]\n",
    "    prod_price_raw = i.__next__().split(\"\\t\")[8]\n",
    "prod_names = prod_name_raw.split(\";\")\n",
    "prod_prices = prod_price_raw.split(\";\")\n",
    "final_list = []\n",
    "# for i in range(len(prod_names)):\n",
    "#     if [prod_names[i], prod_prices[i]] not in final_list:\n",
    "#         final_list.append([prod_names[i], prod_prices[i]])\n",
    "prod_name_raw\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data.csv\") as file:\n",
    "    i = iter(file)\n",
    "    header = i.__next__().strip().split()\n",
    "    raw_list = i.__next__().split(\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 'Alice Mutton', '39', 6),\n",
       " (2, 'Aniseed Syrup', '10', 2),\n",
       " (3, 'Boston Crab Meat', '18.4', 8),\n",
       " (4, 'Camembert Pierrot', '34', 4),\n",
       " (5, 'Carnarvon Tigers', '62.5', 8),\n",
       " (6, 'Chai', '18', 1),\n",
       " (7, 'Chang', '19', 1),\n",
       " (8, 'Chartreuse verte', '18', 1),\n",
       " (9, \"Chef Anton's Cajun Seasoning\", '22', 2),\n",
       " (10, \"Chef Anton's Gumbo Mix\", '21.35', 2),\n",
       " (11, 'Chocolade', '12.75', 3),\n",
       " (12, 'Cote de Blaye', '263.5', 1),\n",
       " (13, 'Escargots de Bourgogne', '13.25', 8),\n",
       " (14, 'Filo Mix', '7', 5),\n",
       " (15, 'Flotemysost', '21.5', 4),\n",
       " (16, 'Geitost', '2.5', 4),\n",
       " (17, 'Genen Shouyu', '15.5', 2),\n",
       " (18, 'Gnocchi di nonna Alice', '38', 5),\n",
       " (19, 'Gorgonzola Telino', '12.5', 4),\n",
       " (20, \"Grandma's Boysenberry Spread\", '25', 2),\n",
       " (21, 'Gravad lax', '26', 8),\n",
       " (22, 'Guarana Fantastica', '4.5', 1),\n",
       " (23, 'Gudbrandsdalsost', '36', 4),\n",
       " (24, 'Gula Malacca', '19.45', 2),\n",
       " (25, 'Gumbar Gummibarchen', '31.23', 3),\n",
       " (26, \"Gustaf's Knackebrod\", '21', 5),\n",
       " (27, 'Ikura', '31', 8),\n",
       " (28, 'Inlagd Sill', '19', 8),\n",
       " (29, 'Ipoh Coffee', '46', 1),\n",
       " (30, \"Jack's New England Clam Chowder\", '9.65', 8),\n",
       " (31, 'Konbu', '6', 8),\n",
       " (32, 'Lakkalikoori', '18', 1),\n",
       " (33, 'Laughing Lumberjack Lager', '14', 1),\n",
       " (34, 'Longlife Tofu', '10', 7),\n",
       " (35, 'Louisiana Fiery Hot Pepper Sauce', '21.05', 2),\n",
       " (36, 'Louisiana Hot Spiced Okra', '17', 2),\n",
       " (37, 'Manjimup Dried Apples', '53', 7),\n",
       " (38, 'Mascarpone Fabioli', '32', 4),\n",
       " (39, 'Maxilaku', '20', 3),\n",
       " (40, 'Mishi Kobe Niku', '97', 6),\n",
       " (41, 'Mozzarella di Giovanni', '34.8', 4),\n",
       " (42, 'Nord-Ost Matjeshering', '25.89', 8),\n",
       " (43, 'Northwoods Cranberry Sauce', '40', 2),\n",
       " (44, 'NuNuCa Nu-Nougat-Creme', '14', 3),\n",
       " (45, 'Original Frankfurter grune Soe', '13', 2),\n",
       " (46, 'Outback Lager', '15', 1),\n",
       " (47, 'Pate chinois', '24', 6),\n",
       " (48, 'Pavlova', '17.45', 3),\n",
       " (49, 'Perth Pasties', '32.8', 6),\n",
       " (50, 'Queso Cabrales', '21', 4),\n",
       " (51, 'Queso Manchego La Pastora', '38', 4),\n",
       " (52, 'Raclette Courdavault', '55', 4),\n",
       " (53, 'Ravioli Angelo', '19.5', 5),\n",
       " (54, 'Rhonbrau Klosterbier', '7.75', 1),\n",
       " (55, 'Rod Kaviar', '15', 8),\n",
       " (56, 'Rogede sild', '9.5', 8),\n",
       " (57, 'Rossle Sauerkraut', '45.6', 7),\n",
       " (58, 'Sasquatch Ale', '14', 1),\n",
       " (59, 'Schoggi Schokolade', '43.9', 3),\n",
       " (60, 'Scottish Longbreads', '12.5', 3),\n",
       " (61, 'Singaporean Hokkien Fried Mee', '14', 5),\n",
       " (62, \"Sir Rodney's Marmalade\", '81', 3),\n",
       " (63, \"Sir Rodney's Scones\", '10', 3),\n",
       " (64, \"Sirop d'erable\", '28.5', 2),\n",
       " (65, 'Spegesild', '12', 8),\n",
       " (66, 'Steeleye Stout', '18', 1),\n",
       " (67, 'Tarte au sucre', '49.3', 3),\n",
       " (68, 'Teatime Chocolate Biscuits', '9.2', 3),\n",
       " (69, 'Thuringer Rostbratwurst', '123.79', 6),\n",
       " (70, 'Tofu', '23.25', 7),\n",
       " (71, 'Tourtiere', '7.45', 6),\n",
       " (72, 'Tunnbrod', '9', 5),\n",
       " (73, \"Uncle Bob's Organic Dried Pears\", '30', 7),\n",
       " (74, 'Valkoinen suklaa', '16.25', 3),\n",
       " (75, 'Vegie-spread', '43.9', 2),\n",
       " (76, 'Wimmers gute Semmelknodel', '33.25', 5),\n",
       " (77, 'Zaanse koeken', '9.5', 3)]"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "product_list = []\n",
    "names = raw_list[5].split(\";\")\n",
    "prices = raw_list[8].split(\";\")\n",
    "id = raw_list[6].split(\";\")\n",
    "for i in range(len(raw_list[8].split(\";\"))):\n",
    "    if [names[i], prices[i], productcategory_to_productcategoryid_dictionary[id[i]]] not in product_list:\n",
    "        product_list.append([names[i], prices[i], productcategory_to_productcategoryid_dictionary[id[i]]])\n",
    "product_list.sort()\n",
    "\n",
    "for i in range(len(product_list)):\n",
    "        product_list[i] = (i+1, product_list[i][0], product_list[i][1],product_list[i][2])\n",
    "product_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Alice Mutton': 1,\n",
       " 'Aniseed Syrup': 2,\n",
       " 'Boston Crab Meat': 3,\n",
       " 'Camembert Pierrot': 4,\n",
       " 'Carnarvon Tigers': 5,\n",
       " 'Chai': 6,\n",
       " 'Chang': 7,\n",
       " 'Chartreuse verte': 8,\n",
       " \"Chef Anton's Cajun Seasoning\": 9,\n",
       " \"Chef Anton's Gumbo Mix\": 10,\n",
       " 'Chocolade': 11,\n",
       " 'Cote de Blaye': 12,\n",
       " 'Escargots de Bourgogne': 13,\n",
       " 'Filo Mix': 14,\n",
       " 'Flotemysost': 15,\n",
       " 'Geitost': 16,\n",
       " 'Genen Shouyu': 17,\n",
       " 'Gnocchi di nonna Alice': 18,\n",
       " 'Gorgonzola Telino': 19,\n",
       " \"Grandma's Boysenberry Spread\": 20,\n",
       " 'Gravad lax': 21,\n",
       " 'Guarana Fantastica': 22,\n",
       " 'Gudbrandsdalsost': 23,\n",
       " 'Gula Malacca': 24,\n",
       " 'Gumbar Gummibarchen': 25,\n",
       " \"Gustaf's Knackebrod\": 26,\n",
       " 'Ikura': 27,\n",
       " 'Inlagd Sill': 28,\n",
       " 'Ipoh Coffee': 29,\n",
       " \"Jack's New England Clam Chowder\": 30,\n",
       " 'Konbu': 31,\n",
       " 'Lakkalikoori': 32,\n",
       " 'Laughing Lumberjack Lager': 33,\n",
       " 'Longlife Tofu': 34,\n",
       " 'Louisiana Fiery Hot Pepper Sauce': 35,\n",
       " 'Louisiana Hot Spiced Okra': 36,\n",
       " 'Manjimup Dried Apples': 37,\n",
       " 'Mascarpone Fabioli': 38,\n",
       " 'Maxilaku': 39,\n",
       " 'Mishi Kobe Niku': 40,\n",
       " 'Mozzarella di Giovanni': 41,\n",
       " 'Nord-Ost Matjeshering': 42,\n",
       " 'Northwoods Cranberry Sauce': 43,\n",
       " 'NuNuCa Nu-Nougat-Creme': 44,\n",
       " 'Original Frankfurter grune Soe': 45,\n",
       " 'Outback Lager': 46,\n",
       " 'Pate chinois': 47,\n",
       " 'Pavlova': 48,\n",
       " 'Perth Pasties': 49,\n",
       " 'Queso Cabrales': 50,\n",
       " 'Queso Manchego La Pastora': 51,\n",
       " 'Raclette Courdavault': 52,\n",
       " 'Ravioli Angelo': 53,\n",
       " 'Rhonbrau Klosterbier': 54,\n",
       " 'Rod Kaviar': 55,\n",
       " 'Rogede sild': 56,\n",
       " 'Rossle Sauerkraut': 57,\n",
       " 'Sasquatch Ale': 58,\n",
       " 'Schoggi Schokolade': 59,\n",
       " 'Scottish Longbreads': 60,\n",
       " 'Singaporean Hokkien Fried Mee': 61,\n",
       " \"Sir Rodney's Marmalade\": 62,\n",
       " \"Sir Rodney's Scones\": 63,\n",
       " \"Sirop d'erable\": 64,\n",
       " 'Spegesild': 65,\n",
       " 'Steeleye Stout': 66,\n",
       " 'Tarte au sucre': 67,\n",
       " 'Teatime Chocolate Biscuits': 68,\n",
       " 'Thuringer Rostbratwurst': 69,\n",
       " 'Tofu': 70,\n",
       " 'Tourtiere': 71,\n",
       " 'Tunnbrod': 72,\n",
       " \"Uncle Bob's Organic Dried Pears\": 73,\n",
       " 'Valkoinen suklaa': 74,\n",
       " 'Vegie-spread': 75,\n",
       " 'Wimmers gute Semmelknodel': 76,\n",
       " 'Zaanse koeken': 77}"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalized_database_filename = \"normalized.db\"\n",
    "conn = create_connection(normalized_database_filename)\n",
    "sql_statement = \"SELECT ProductName, ProductID from Product\"\n",
    "prodname_from_table = execute_sql_statement(sql_statement, conn)\n",
    "\n",
    "product_to_productid_dictionary = {}\n",
    "\n",
    "for i in range(len(prodname_from_table)):\n",
    "    product_to_productid_dictionary[prodname_from_table[i]\n",
    "                                    [0]] = prodname_from_table[i][1]\n",
    "\n",
    "product_to_productid_dictionary"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cd78fef2128015050713e82ca51c6520b11aee7c9ee8df750520bbbc7384cbaa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
